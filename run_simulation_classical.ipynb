{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.classical_classifiers import RBF_SVM, confusion_values, accuracy_from_confusion_values\n",
    "import numpy as np\n",
    "from lib.cloud_classification_data import get_scene, get_scene_mask, import_scene_names, unzeropad\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access training and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('../38-Cloud_test')\n",
    "scenes_path = base_path/'test_sceneids_38-Cloud.csv'\n",
    "scene_names = import_scene_names(scenes_path)\n",
    "\n",
    "# The training data files\n",
    "# The training data is prepared with the superpixel segmentation technique.\n",
    "# Each data point is obtained with superpixel segmentation from the full training data set.\n",
    "# The features are: \n",
    "#    'R_med', 'G_med', 'B_med', 'Nir_med',\n",
    "#    'R_avg', 'G_avg', 'B_avg', 'Nir_avg',\n",
    "#    'R_iqr', 'G_iqr', 'B_iqr', 'Nir_iqr',\n",
    "#    'R_max', 'G_max', 'B_max', 'Nir_max',\n",
    "#    'R_min', 'G_min', 'B_min', 'Nir_min',\n",
    "#    'R_std', 'G_std', 'B_std', 'Nir_std',\n",
    "#    'gt_avg'\n",
    "\n",
    "train_path = 'experiment_tr_data/*train*' \n",
    "train_files = sorted(glob.glob(train_path))\n",
    "validate_files = [s.replace('train', 'validate') for s in train_files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one file from training set\n",
    "file_id = 0\n",
    "\n",
    "# Choose hyperparameter range for the validation grid search\n",
    "gamma_range = (0.1,150,3)# (min, max, step)\n",
    "C_range = (0.1,150,3)# (min, max, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "print(file_id+1, ' of ', len(train_files))\n",
    "train = pd.read_csv(train_files[file_id]).to_numpy()\n",
    "x_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "\n",
    "# Get validation data\n",
    "validate = pd.read_csv(validate_files[file_id]).to_numpy()\n",
    "x_validate = validate[:,:-1]\n",
    "y_validate = validate[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RBF_SVM(gamma = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf.validate(x_train, y_train, x_validate, y_validate, C_range, gamma_range, info=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict scene"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose and import scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = 0\n",
    "\n",
    "# Get scene data\n",
    "scene_data, r_max, c_max, patches_ids_array, scene_names = get_scene(base_path, scene_id)\n",
    "\n",
    "# Get scene ground-truth\n",
    "gt_path = Path('../38-Cloud_test/Entire_scene_gts')\n",
    "gt_scene = get_scene_mask(gt_path, scene_names, scene_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rbf.predict_scene_sp(scene_data=scene_data, r_max=r_max, c_max=c_max, array_of_patches_indices=patches_ids_array, scene_name=scene_names[scene_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predition with ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction has to be trimmed to ground-truth size\n",
    "trimmed_pr_gt = unzeropad(pred,gt_scene)\n",
    "\n",
    "conf_val = confusion_values(trimmed_pr_gt, gt_scene)\n",
    "rbf.export_scene_prediction_results(confusion_values=conf_val, dataset_name = 'SP')\n",
    "print('Finished prediction! Scene: ', scene_names[scene_id])\n",
    "print('Scene accurancy: ', accuracy_from_confusion_values(conf_val=conf_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8f4dd9a8150c7db870e9b968ad12732ff3cb84f2df7f35b4515c2f72f48714f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
